\section{Discussion}
\label{sec:Discussion}

\subsection{Search Traversal}
\label{sub:Search Traversal}

The puzzle is solved using the \texttt{SearchMethod} protocol's
\texttt{traverse:} method, which is inherited via protocol extension to all
concrete implementations of the variant search methods defined in
Section~\ref{sub:Search Algorithms}. Refer to Listing~\ref{lst:searchtraversal}
below for the implementation of search traversal.

Depending on on the search's frontier type which is used in the search, the
search will alter the way in which nodes are popped and pushed to and from the
frontier. Refer to Section~\ref{sub:Frontiers} for more.

\lstinputlisting[
  label=lst:searchtraversal,
  caption=
    Search traversal for searches use the following code,
  language=swift,
  linerange=62-100
]{../../src/SearchMethod.swift}

\subsection{Iterative Depth Search Implementation}
\label{sub:Iterative Depth Search Implementation}

Where an iterative depth search is used, the pushing and popping of a fontier
may cause a node to be pushed to it's \emph{fallback} frontier (a FIFO frontier),
that is, the frontier that stores all nodes that exceed the current threshold.

An iterative search with threshold, $t$, a concrete frontier, $f$, and a
fallback frontier $\bar{f}$ would use thje node threshold comparator
function\footnote{Both comparators for \texttt{IDAS} and \texttt{IDS} are noted
in Section~\ref{subs:Thresholds}.}, $T(n)$, to calculate values from a node,
$n$, and see which frontier should be used. Thus:
\begin{align}\label{eq:frontiercalc}
        f =& \ \{ \ n \ | \ T(n) < t    \ \}     \\
  \bar{f} =& \ \{ \ n \ | \ T(n) \geq t \ \}
\end{align}

Hence, for example, consider the following where each frontier's nodes are
mapped to its original $T(n)$ values for $t=4$:
\begin{align*}
      f  \mapsto T(n) =& \ \{ \ 1 , 2 , 2 , 3 , 3 , 3 \ \}\\
 \bar{f} \mapsto T(n) =& \ \{ \ 4 , 6 , 7 , 7 , 8 , 8 , 10, 11 \ \}
\end{align*}

Eventually, all nodes in $f$ will reduce to an empty set after the frontier is
fully popped of all its nodes. When this occurs, the threshold doubles to 8.
All nodes in $\bar{f}$ are re-evaluated according to Equation~\ref{eq:frontiercalc}
and the next iteration occurs:
\begin{align*}
       f  \mapsto T(n) =& \ \{ \ 4 , 6 , 7 , 7  \ \}\\
  \bar{f} \mapsto T(n) =& \ \{ \ 8 , 8 , 10, 11 \ \}
\end{align*}

Note that Equation~\ref{eq:frontiercalc} will always apply to nodes to decide
which frontier they are to be allocated to. This is demonstrated in
Listings~\ref{lst:iterativedeeppop} and \ref{lst:iterativedeeppush}.

\lstinputlisting[
  label=lst:iterativedeeppop,
  caption=
    Pushing a node in an iterative deepening search's frontier must perform
    $T(n)$ to see \emph{which} frontier that node should be inserted to,
  language=swift,
  linerange=55-67
]{../../src/IterativeDeepeningSearchMethod.swift}

\lstinputlisting[
  label=lst:iterativedeeppush,
  caption=
    Popping a node in an iterative deepening search see if $f$ is empty and if
    so double the threshold and reapply Equation~\ref{eq:frontiercalc} to
    $\bar{f}$,
  language=swift,
  linerange=69-111
]{../../src/IterativeDeepeningSearchMethod.swift}

\subsection{Frontiers}
\label{sub:Frontiers}

There are four frontiers in the program, namely:

\begin{itemize}
  \item a FIFO frontier used for \texttt{BFS} search,
  \item a LIFO frontier used for \texttt{DFS} and \texttt{IDS} searches,
  \item an evaluated frontier used for informed searches, and
  \item a random frontier used for \text{BOGO} search.
\end{itemize}

The evaluated frontier will use an evaluation function to decide the index
in which to insert in its collection, as shown in Listing~\ref{lst:indexinsert}.

\lstinputlisting[
  label=lst:indexinsert,
  caption=
    Implementation of inserting at the correct index for evaluated frontier;
    the collection ensures that nodes are inserted by their distance to goal,
  language=swift,
  linerange=48-69
]{../../src/EvaluatedFrontier.swift}

\subsection{Random State Generation}
\label{sub:random state generation}

As you can see in \texttt{RandomState.swift}, random $n$ by $m$ states were
generated for extensive testing. It was ensured that these generated states are
\emph{solvable} using a State's \texttt{isSolvable} computed property.

To implement \texttt{isSolveable}, three theorms devised by
\citeauthor{gong2000} were used. The number of inversions, $k$, of a state is
calculated by of a state, $s$ by finding the sum of the each tile, $t$, at index
$i$ that is higher than the \emph{next} tile position, $t_{i+1}$.

\begin{equation}\label{eq:inversions}
  k(s) = \sum_{i=0}^{n \times m} \ ( \
    \mathbf{ count } ( \ K \ )
  \ ) \ \text{where} \ K = \{ \ t \ | \ t_{i} > t_{i+1} \ \text{and} \ t_{i} \neq 0 \ \}
\end{equation}

The implementation of Equation~\ref{eq:inversions} is given in Listing~\ref{lst:solveable1}

\lstinputlisting[
  label=lst:solveable1,
  caption=
    Calculating the number of inversions of a given state,
  language=swift,
  linerange=153-162
]{../../src/State.swift}

By using Equation~\ref{eq:inversions}, we can then utilise three theorms to see
if a given state is solvable. Theorms 2 and 3 make use of the number of
the row of the blank, $i$, file from the bottom of the row, that is, for an $n \times m$
state $m - i$.

\paragraph{Theorm 1}
\label{par:Theorm 1}

``If $n$ is odd, then every legal configuration corresponds to a sequence with an even number of inversions'':
\begin{equation}
  n \not\equiv k(s) \ (\text{mod}\ 2) \quad \text{where} \ n \ \text{mod} \ 2 \neq 0
\end{equation}

\paragraph{Theorm 2}
\label{par:Theorm 2}

``If n is even, then every legal configuration with the blank tile in the
$i$'th row where $m-i$ is even corresponds to a sequence with an even
number of inversions'':
\begin{equation}
  n \equiv m-i \ (\text{mod}\ 2) \equiv k(s) \ (\text{mod}\ 2) \quad \text{where} \ n \ \text{mod} \ 2 = 0
\end{equation}

\paragraph{Theorm 3}
\label{par:Theorm 3}

``If $n$ is even, then every legal configuration with the blank tile in the
$i$'th row where $m-i$ is odd corresponds to a sequence with an odd
number of inversions'':
\begin{equation}
  n \not\equiv m-i \ (\text{mod}\ 2) \equiv k(s) \ (\text{mod}\ 2) \quad \text{where} \ n \ \text{mod} \ 2 = 0
\end{equation}

Refer to
\texttt{State.swift:140-204} for the three theorms used to calculate solvability
and \texttt{IsStateSolvableTests.swift} for test coverage of these theorms.

\subsection{Time Performance Testing}
\label{sub:time performance tests}

The codebase was ensured for optimal unit test coverage. For tests, refer to
the the \texttt{test} directory. Each test generated a random state of a variant
state size as demonstrated in Section~\ref{sub:random state generation}, and the
results were averaged over 10 different tests for each.

Results from aggregating these time performance tests are
shown in Tables~\ref{tab:uninformed} to \ref{tab:gbfs} and are graphically
represented in Figures~\ref{fig:unformed} to \ref{fig:gbfs}. All tests for
iterative deepening searches had an initial threshold value of 4.

On analysis of Figures~\ref{fig:unformed}, it can be determined that the $3 \times 3$
states take the longest for most tests. The maximum number of solvable states,
$n$, as shown by \citet{gong2000}, is shown in \ref{eq:maxsolvable}:

\begin{equation}\label{eq:maxsolvable}
  n_{n \times m} = \frac{(n \times m)!}{2}
\end{equation}

For the $3 \times 3$ tests, it can be shown that there are more legal configurations
than the largest other dimensional state, $4 \times 2$ by applying \ref{eq:maxsolvable}
on each state to prove \ref{eq:3by3larger}:

\begin{equation}\label{eq:3by3larger}
  n_{3 \times 3} = \frac{( 3 \times 3 )!}{2} = 181440 > n_{2 \times 4} = \frac{( 2 \times 4 )!}{2} = 20160
\end{equation}

Figure~\ref{fig:results}(b) highlights that \texttt{IDS} is indeed the slowest
implemented algorithm, taking up to 110s to solve for a $3 \times 3$ puzzle. This
may be caused by expensively implemented operations defined in
Section~\ref{sub:Iterative Depth Search Implementation}.

Factoring this outlier out---see Figure~\ref{fig:results}(a)---the \texttt{BFS} performs
best on each of the tests, followed second by \texttt{BOGO} and lastly \texttt{DFS}.

Similarly, the iterative-deepening A* search (\texttt{IDAS}) is also slower
than its non-depth-limited counterpart \texttt{AS}. Whilst \texttt{IDAS} is still far
improved than \texttt{GBFS} as shown in the summary Figure~\ref{fig:results}(f),
there are cases where A* performs faster.

Figures~\ref{fig:results}(c) to Figures~\ref{fig:results}(g) also show that the Chebyshev
distance is consistently the slowest-calculating heursitic to use for informed
searches. Manhattan and Euclidean distances are shown to be faster; this may
be due to their simplier implementations.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{graph/uninformed.pdf}
  \caption{Aggregated performance test results for uninformed search methods}
  \label{fig:uninformed}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{graph/informed.pdf}
  \caption{Aggregated performance test results for informed search methods averaged over all heuristics}
  \label{fig:informed}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{graph/as.pdf}
  \caption{Aggregated performance test results for A* over all heuristics}
  \label{fig:as}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{graph/idas.pdf}
  \caption{Aggregated performance test results for IDA* over all heuristics}
  \label{fig:idas}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{graph/gbfs.pdf}
  \caption{Aggregated performance test results for GBFS over all heuristics}
  \label{fig:gbfs}
\end{figure}
